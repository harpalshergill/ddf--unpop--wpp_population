{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "#from xlrd import open_workbook\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from ddf_utils.str import to_concept_id\n",
    "from ddf_utils.datapackage import create_datapackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#out_dir = '../../'\n",
    "out_dir = '../'\n",
    "\n",
    "# global variables to build data for concepts and entities\n",
    "variants = []\n",
    "agegroups = []\n",
    "age1YrInterval = []\n",
    "ageBroad = []\n",
    "age5YrInterval = []\n",
    "ref_AreaCode = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to create directory if it does not exist\n",
    "def createDirectory(Directory):\n",
    "    if not os.path.exists('../'+Directory.lower()):\n",
    "        os.makedirs('../'+Directory.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_Files_new(source, variant, gender, TypeBy, NewFormatInfo):\n",
    "    #load file using pandas\n",
    "    data = pd.read_excel(source, sheetname= variant, skiprows=16, na_values='â€¦')\n",
    "    data = data.drop(['Index', 'Notes'], axis = 1)\n",
    "    \n",
    "    #remove the empty space and convert '-' to '_' char\n",
    "    data['Variant'] = data['Variant'].str.lower().replace(' ', '_').replace('-','_')\n",
    "    \n",
    "    #print(data.Variant.unique())\n",
    "    \n",
    "    #rename country column and country code column\n",
    "    data = data.rename(columns={\n",
    "        'Major area, region, country or area *': 'Ref_Area',\n",
    "        'Country code': 'Ref_Area_Code',\n",
    "        'Reference date (1 January - 31 December)': 'Year'\n",
    "    })\n",
    "    \n",
    "    #update columns name from NewFormatInfo file\n",
    "    for i, row in enumerate(NewFormatInfo.values):\n",
    "        IndicatorInitial, IndicatorDest, DestFolder = row\n",
    "        if(\";\" in IndicatorInitial):\n",
    "            if(IndicatorDest == \"TotalDeaths\"):\n",
    "                data = data.rename(columns={\n",
    "                        \"Male deaths (thousands)\" : \"TotalDeaths_Male\",\n",
    "                        \"Female deaths (thousands)\" : \"TotalDeaths_Female\"\n",
    "                    })\n",
    "            elif(IndicatorDest == \"LifeExpectancyAtBirth\"):\n",
    "                data = data.rename(columns={\n",
    "                        \"Life expectancy at birth, males (years)\" : \"LifeExpectancyAtBirth_Male\",\n",
    "                        \"Life expectancy at birth, females (years)\" : \"LifeExpectancyAtBirth_Female\"\n",
    "                    })\n",
    "        else:\n",
    "            data = data.rename(columns={IndicatorInitial : IndicatorDest})\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetDataFromWorkBook(source, gender, indicator, TypeBy, NewFormatInfo):\n",
    "    all_variants = []\n",
    "\n",
    "    #pandas excel file fun.\n",
    "    wbb = pd.ExcelFile(source)\n",
    "\n",
    "    #iterate through each SHEET except \"NOTES\"\n",
    "    for sheetName in wbb.sheet_names:\n",
    "        if(sheetName == 'NOTES'):\n",
    "            #ignore NOTES sheet since we are not collecting metadata yet\n",
    "            continue\n",
    "        else:\n",
    "            #first load the files\n",
    "            mydata = load_Files_new(source, sheetName, gender, TypeBy, NewFormatInfo)\n",
    "            mydata = mydata.drop(['Ref_Area'], axis=1)\n",
    "            #mydata = mydata.set_index(['Ref_Area_Code','Variant', 'Year'])\n",
    "            all_variants.append(mydata)\n",
    "    return all_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataFiles_new(ds, NewFormatInfo, Ref_Area_List):\n",
    "    for i, row in enumerate(NewFormatInfo.values):\n",
    "        IndicatorInitial, IndicatorDest, DestFolder = row\n",
    "        \n",
    "        ds.columns = list(map(to_concept_id, ds.columns))\n",
    "        \n",
    "        ds['variant'] = [ x.replace(' ', '_').replace('-','_') for x in ds['variant']]\n",
    "    \n",
    "        \n",
    "        Directory = DestFolder.lower().replace('newformat', IndicatorDest.lower())\n",
    "        #print(Directory)\n",
    "        newFileName = Directory.lower()\n",
    "        newFileName = newFileName.replace(\"ref_area_code\", \"ref_area_code-{}\")\n",
    "        newFileName = newFileName + \".csv\"\n",
    "        \n",
    "        ds_all = ds[['variant','ref_area_code','year',IndicatorDest.lower()]].copy()\n",
    "        \n",
    "        #if IndicatorInitial contain ;\n",
    "        if(\";\" in IndicatorInitial):\n",
    "            if(IndicatorDest == \"TotalDeaths\"):\n",
    "                ds_all_1 = ds[['variant','ref_area_code','year','totaldeaths_male']].copy()\n",
    "                ds_all_1.columns = ['variant','ref_area_code','year','totaldeaths']\n",
    "                ds_all_1['gender'] = 'male'\n",
    "                \n",
    "                ds_all_2 = ds[['variant','ref_area_code','year','totaldeaths_female']].copy()\n",
    "                ds_all_2.columns = ['variant','ref_area_code','year','totaldeaths']\n",
    "                ds_all_2['gender'] = 'female'\n",
    "                \n",
    "                frames = [ds_all_1, ds_all_2]\n",
    "                ds_all = pd.concat(frames)\n",
    "            elif(IndicatorDest == \"LifeExpectancyAtBirth\"):\n",
    "                ds_all_1 = ds[['variant','ref_area_code','year','lifeexpectancyatbirth_male' ]].copy()\n",
    "                ds_all_1.columns = ['variant','ref_area_code','year','totaldeaths']\n",
    "                ds_all_1['gender'] = 'male'\n",
    "                ds_all_2 = ds[['variant','ref_area_code','year','lifeexpectancyatbirth_female' ]].copy()\n",
    "                ds_all_2.columns = ['variant','ref_area_code','year','totaldeaths']\n",
    "                ds_all_2['gender'] = 'female'\n",
    "                frames = [ds_all_1, ds_all_2]\n",
    "                ds_all = pd.concat(frames)\n",
    "        \n",
    "        # group data by ref_area_code as files are generated by this grouping\n",
    "        for geo, idxs in ds_all.groupby(by='ref_area_code').groups.items():\n",
    "            myDS = ds_all.ix[idxs]\n",
    "\n",
    "            data = Ref_Area_List.loc[Ref_Area_List['Code'] == geo]\n",
    "            # update the directory and file names based on geo in country, continent, region or global\n",
    "            if(data.iloc[0]['is--world'] == 1):\n",
    "                NewDirectory = Directory.replace('ref_area_code','global')\n",
    "                newFileName = newFileName.replace('ref_area_code','global')\n",
    "                myDS = myDS.rename(columns={\n",
    "                    'ref_area_code': 'global'\n",
    "                })\n",
    "            elif (data.iloc[0]['is--region'] == 1):\n",
    "                NewDirectory = Directory.replace('ref_area_code','region')\n",
    "                newFileName = newFileName.replace('ref_area_code','region')\n",
    "                myDS = myDS.rename(columns={\n",
    "                    'ref_area_code': 'region'\n",
    "                })\n",
    "            elif (data.iloc[0]['is--continent'] == 1):\n",
    "                NewDirectory = Directory.replace('ref_area_code','continent')\n",
    "                newFileName = newFileName.replace('ref_area_code','continent')\n",
    "                myDS = myDS.rename(columns={\n",
    "                    'ref_area_code': 'continent'\n",
    "                })\n",
    "            elif (data.iloc[0]['is--country'] == 1):\n",
    "                NewDirectory = Directory.replace('ref_area_code','country')\n",
    "                newFileName = newFileName.replace('ref_area_code','country')\n",
    "                myDS = myDS.rename(columns={\n",
    "                    'ref_area_code': 'country'\n",
    "                })\n",
    "\n",
    "            createDirectory(NewDirectory)\n",
    "            path = os.path.join(out_dir,NewDirectory+'/'+newFileName.format(geo))\n",
    "\n",
    "            myDS.to_csv(path, index=False, float_format='%.15g')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MAIN Function. Calls the metadata.xslx file and iterate through each file\n",
    "#supports reading multiple files and concatenating them to one dataset as well.\n",
    "def callDataPointFiles(metadata_df, cdf):\n",
    "    Ref_Area_List = pd.read_excel('source/countrymetadata.xlsx', parse_cols = \"A:G\")\n",
    "    NewFormatInfo = pd.read_excel ('source/NewFormatInfo.xlsx', parse_cols = \"A:C\")\n",
    "    df = metadata_df\n",
    "    MainStart = time.time()\n",
    "    for i, row in enumerate(metadata_df.values):\n",
    "        start = time.time()\n",
    "        \n",
    "        #date = metadata_df.index[i]\n",
    "        FileName, TypeBY, SEX, Indicator, Directory, Include, name, description, url = row\n",
    "        newFileName = Directory.lower()\n",
    "        newFileName = newFileName.replace(\"ref_area_code\", \"ref_area_code-{}\")\n",
    "        newFileName = newFileName + \".csv\"\n",
    "\n",
    "        if(Include == 1):\n",
    "            #load the file\n",
    "            ds1 = GetDataFromWorkBook(\"source/\"+FileName, SEX, Indicator, TypeBY, NewFormatInfo )\n",
    "            ds = pd.concat(ds1, ignore_index = True)\n",
    "            #print(ds.head(3))\n",
    "            createDataFiles_new(ds, NewFormatInfo, Ref_Area_List)\n",
    "        \n",
    "    FinalEnd = time.time()\n",
    "    print ('Total Time For All Files: ' + str(FinalEnd-MainStart))\n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time For All Files: 25.225170135498047\n"
     ]
    }
   ],
   "source": [
    "metadata_df = pd.read_excel('source/metadata.xlsx', parse_cols = \"A:F\")\n",
    "metadata_df['name'] = ''\n",
    "metadata_df['description'] = ''\n",
    "metadata_df['sourceurl'] = 'https://esa.un.org/unpd/wpp/Download/Standard/Population/'\n",
    "\n",
    "cdf = callDataPointFiles(metadata_df, cdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
