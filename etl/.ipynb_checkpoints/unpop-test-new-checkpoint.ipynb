{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "from xlrd import open_workbook\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from ddf_utils.str import to_concept_id\n",
    "from ddf_utils.index import create_datapackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#out_dir = '../../'\n",
    "out_dir = '../'\n",
    "\n",
    "# data to hold all the values\n",
    "variants = []\n",
    "#['CONSTANT-FERTILITY', 'ZERO-MIGRATION', 'NOTES', 'HIGH VARIANT', 'ESTIMATES', 'MEDIUM VARIANT', 'NO CHANGE', 'CONSTANT-MORTALITY', 'INSTANT-REPLACEMENT', 'LOW VARIANT']\n",
    "agegroups = []\n",
    "age1YrInterval = []\n",
    "ageBroad = []\n",
    "age5YrInterval = []\n",
    "#['0', '1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '80+', '9', '100+', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '0-4', '10-14', '15-19', '20-24', '25-29', '30-34', '35-39', '40-44', '45-49', '5-9', '50-54', '55-59', '60-64', '65-69', '70-74', '75-79', '80-84', '85-89', '90-94', '95-99', '0-1', '0-14', '0-17', '0-19', '0-24', '11-16', '11-17', '11-18', '12-14', '12-16', '12-17', '12-18', '13-17', '13-18', '13-19', '15+', '15-17', '15-24', '15-49', '15-59', '15-64', '16+', '17+', '18+', '18-23', '20+', '20-64', '20-69', '21+', '25+', '25-49', '25-64', '25-69', '3-4', '3-5', '3-6', '4-5', '4-6', '5-10', '5-11', '5-14', '50+', '6-10', '6-11', '6-12', '6-9', '60+', '65+', '7-10', '7-12', '70+', '75+', 'Total', '85+', '90+']\n",
    "ref_AreaCode = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#method to read files in a folder...\n",
    "#onlyfiles = [f for f in listdir('source/byYearInterval') if isfile(join('source/byYearInterval', f))]\n",
    "#onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDirectory(Directory):\n",
    "    if not os.path.exists('../'+Directory.lower()):\n",
    "        os.makedirs('../'+Directory.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate files from the data points.\n",
    "def GenerateYearFormatFiles(ds_all, Directory, FileNameWithPath, gender, Ref_Area_List):\n",
    "    \n",
    "    if (gender.upper() == 'TOTAL') or (gender.upper() == \"NA\"):\n",
    "        ds_all = ds_all.drop('gender', axis=1)\n",
    "\n",
    "    for geo, idxs in ds_all.groupby(by='ref_area_code').groups.items():\n",
    "        myDS = ds_all.ix[idxs]\n",
    "\n",
    "        #print(myDS.head(2))\n",
    "        \n",
    "        if(\"agebroad\" in Directory.lower()):\n",
    "            myDS = myDS.rename(columns={\n",
    "                'age': 'agebroad'\n",
    "            })\n",
    "        elif(\"age1yearinterval\" in Directory.lower()):\n",
    "            myDS = myDS.rename(columns={\n",
    "                'age': 'age1yearinterval'\n",
    "            })\n",
    "        elif(\"age5yearinterval\" in Directory.lower()):\n",
    "            myDS = myDS.rename(columns={\n",
    "                'age': 'age5yearinterval'\n",
    "            })\n",
    "        \n",
    "        \n",
    "        data = Ref_Area_List.loc[Ref_Area_List['Code'] == geo]\n",
    "        #print(data)\n",
    "        #print(data.iloc[0]['is--world'])\n",
    "        if(data.iloc[0]['is--world'] == 1):\n",
    "            NewDirectory = Directory.replace('ref_area_code','global')\n",
    "            NewFileNameWithPath = FileNameWithPath.replace('ref_area_code','global')\n",
    "            myDS = myDS.rename(columns={\n",
    "                'ref_area_code': 'global'\n",
    "            })\n",
    "            #print(NewDirectory)\n",
    "        elif (data.iloc[0]['is--region'] == 1):\n",
    "            NewDirectory = Directory.replace('ref_area_code','region')\n",
    "            NewFileNameWithPath = FileNameWithPath.replace('ref_area_code','region')\n",
    "            myDS = myDS.rename(columns={\n",
    "                'ref_area_code': 'region'\n",
    "            })\n",
    "            #print(NewDirectory)\n",
    "        elif (data.iloc[0]['is--continent'] == 1):\n",
    "            NewDirectory = Directory.replace('ref_area_code','continent')\n",
    "            NewFileNameWithPath = FileNameWithPath.replace('ref_area_code','continent')\n",
    "            myDS = myDS.rename(columns={\n",
    "                'ref_area_code': 'continent'\n",
    "            })\n",
    "            #print(NewDirectory)\n",
    "        elif (data.iloc[0]['is--country'] == 1):\n",
    "            NewDirectory = Directory.replace('ref_area_code','country')\n",
    "            NewFileNameWithPath = FileNameWithPath.replace('ref_area_code','country')\n",
    "            myDS = myDS.rename(columns={\n",
    "                'ref_area_code': 'country'\n",
    "            })\n",
    "        #print(myDS.head(2))\n",
    "\n",
    "        createDirectory(NewDirectory)\n",
    "        path = os.path.join(out_dir,NewDirectory+'/'+NewFileNameWithPath.format(geo))\n",
    "        \n",
    "        #path = os.path.join(out_dir,NewFileNameWithPath.format(geo))\n",
    "        \n",
    "        #to_save = ds_all.ix[idxs]\n",
    "        #to_save.ix[idxs].to_csv(path, index=False, float_format='%.15g')\n",
    "        myDS.to_csv(path, index=False, float_format='%.15g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_Files(source, variant, gender, TypeBy):\n",
    "    #load file using pandas\n",
    "    data = pd.read_excel(source, sheetname= variant, skiprows=16, na_values='â€¦')\n",
    "    data = data.drop(['Index', 'Notes'], axis = 1)\n",
    "    \n",
    "    #remove the empty space and convert '-' to '_' char\n",
    "    data['Variant'] = data['Variant'].str.lower().replace(' ', '').replace('-','')\n",
    "    \n",
    "    #rename country column and country code column\n",
    "    data = data.rename(columns={\n",
    "        'Major area, region, country or area *': 'Ref_Area',\n",
    "        'Country code': 'Ref_Area_Code'\n",
    "    })\n",
    "    #year column is present in Age Type sheets\n",
    "    if (TypeBy == \"Age\"):\n",
    "        data = data.rename(columns={\n",
    "        'Reference date (as of 1 July)': 'Year'\n",
    "    })\n",
    "    #insert Gender column\n",
    "    data.insert(3, 'Gender', gender)\n",
    "    if (TypeBy == \"YearInterval\"):\n",
    "        data.insert(3, 'Freq', '5Yearly')\n",
    "    elif (TypeBy == \"AgeYearInterval\"):\n",
    "        data = data.rename(columns={\n",
    "        'Period': 'Year'\n",
    "        })\n",
    "        #get first year in yyyy-yyyy time period\n",
    "        data['Year'] = data['Year'].str[:4] \n",
    "        data.insert(3, 'Freq', '5Yearly')\n",
    "\n",
    "    #update teh AreaCode entity list\n",
    "    global ref_AreaCode\n",
    "    ref_AreaCode = ref_AreaCode + list(set(data['Ref_Area_Code']) - set(ref_AreaCode))\n",
    "\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetDataFromWorkBookSheets(source, gender, indicator, TypeBy):\n",
    "    all_variants = []\n",
    "\n",
    "    wbb = open_workbook(filename = source)\n",
    "    #add variant concepts\n",
    "    global variants\n",
    "    variants = variants + list(set(wbb.sheet_names()) - set(variants))\n",
    "    \n",
    "    #iterate through each SHEET except \"NOTES\"\n",
    "    for sheetName in wbb.sheet_names():\n",
    "        if(sheetName == 'NOTES'):\n",
    "            #ignore NOTES sheet since we are not collecting metadata yet\n",
    "            continue\n",
    "        else:\n",
    "            #first load the files\n",
    "            mydata = load_Files(source, sheetName, gender, TypeBy)\n",
    "            mydata = mydata.drop(['Ref_Area'], axis=1)\n",
    "            #based on File format type apply the index and set the column value\n",
    "            if (TypeBy == \"Age\"):\n",
    "                mydata = mydata.set_index(['Ref_Area_Code','Year','Variant','Gender'])\n",
    "                mydata.columns.name = 'Age'\n",
    "            elif (TypeBy == \"Year\"):\n",
    "                mydata = mydata.set_index(['Ref_Area_Code','Variant', 'Gender'])\n",
    "                mydata.columns.name = 'Year'\n",
    "            elif (TypeBy == \"YearInterval\"):\n",
    "                mydata = mydata.set_index(['Ref_Area_Code','Variant', 'Gender', 'Freq'])\n",
    "                mydata.columns.name = 'Year'\n",
    "            elif (TypeBy == \"AgeYearInterval\"):\n",
    "                mydata = mydata.set_index(['Ref_Area_Code','Year','Variant','Gender', 'Freq'])\n",
    "                mydata.columns.name = 'Age'\n",
    "            \n",
    "            mydata = mydata.stack().reset_index().rename(columns={0:indicator})\n",
    "            all_variants.append(mydata)\n",
    "            \n",
    "            #break\n",
    "    return all_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#method to sort the file with refArea, Year, Variant, Gender\n",
    "def sortDataSets(dsSet_all, TypeBy, FileName):\n",
    "    dataSet = pd.concat(dsSet_all, ignore_index=True) \n",
    "    dataSet.columns = list(map(to_concept_id, dataSet.columns))\n",
    "    #global agegroups\n",
    "    global age1YrInterval\n",
    "    global ageBroad\n",
    "    global age5YrInterval\n",
    "    \n",
    "    if (TypeBy == \"Age\"): \n",
    "        #update the global age groups with any new values\n",
    "        #print(FileName)\n",
    "        #print((\"age_annual\" in FileName.lower()))\n",
    "        if(\"broad_age\" in FileName.lower()):\n",
    "            ageBroad = ageBroad + list(set(dataSet['age'].unique()) - set(ageBroad))\n",
    "        elif(\"age_annual\" in FileName.lower()):\n",
    "            age1YrInterval = age1YrInterval + list(set(dataSet['age'].unique()) - set(age1YrInterval))\n",
    "        elif(\"_age_\" in FileName.lower()):\n",
    "            age5YrInterval = age5YrInterval + list(set(dataSet['age'].unique()) - set(age5YrInterval))\n",
    "        dataSet.loc[dataSet['age'] == \"80+\", 'age'] = '80plus'\n",
    "        dataSet.loc[dataSet['age'] == \"100+\", 'age'] = '100plus'\n",
    "        \n",
    "        dataSet['age'] = dataSet['age'].astype('category', categories=list(dataSet['age'].unique()), ordered=True)\n",
    "        dataSet = dataSet.sort_values(by=['ref_area_code', 'year','age','variant', 'gender'])\n",
    "    elif (TypeBy == \"Year\"):\n",
    "        dataSet = dataSet.sort_values(by=['ref_area_code', 'year','variant', 'gender'])\n",
    "    elif (TypeBy == \"YearInterval\"):\n",
    "        dataSet['year'] = dataSet['year'].str[:4]\n",
    "        dataSet = dataSet.sort_values(by=['ref_area_code', 'year','variant', 'gender', 'freq'])\n",
    "    elif (TypeBy == \"AgeYearInterval\"):\n",
    "        #agegroups = agegroups + list(set(dataSet['age'].unique()) - set(agegroups))\n",
    "        #update the global age groups with any new values\n",
    "        if(\"broad_age\" in FileName.lower()):\n",
    "            ageBroad = ageBroad + list(set(dataSet['age'].unique()) - set(ageBroad))\n",
    "        elif(\"age_annual\" in FileName.lower()):\n",
    "            age1YrInterval = age1YrInterval + list(set(dataSet['age'].unique()) - set(age1YrInterval))\n",
    "        elif(\"_age_\" in FileName.lower()):\n",
    "            age5YrInterval = age5YrInterval + list(set(dataSet['age'].unique()) - set(age5YrInterval))\n",
    "        \n",
    "        dataSet.loc[dataSet['age'] == \"80+\", 'age'] = '80plus'\n",
    "        dataSet.loc[dataSet['age'] == \"100+\", 'age'] = '100plus'\n",
    "        \n",
    "        dataSet['age'] = dataSet['age'].astype('category', categories=list(dataSet['age'].unique()), ordered=True)\n",
    "        dataSet = dataSet.sort_values(by=['ref_area_code', 'year','age','variant', 'gender', 'freq'])\n",
    "   \n",
    "    return dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateMetaData(df, TypeBY, Directory, FileName, Indicator):\n",
    "    if(\";\" in FileName):\n",
    "        #then get first filename\n",
    "        files = FileName.split(\";\")\n",
    "        FileName = files[0]\n",
    "    \n",
    "    #read the excel file to get indicator and description\n",
    "    if(TypeBY == 'Age'or TypeBY == \"AgeYearInterval\"):\n",
    "        myDSvals = pd.read_excel(\"source/\"+FileName, sheetname='ESTIMATES', skiprows=9, nrows=16 ,  header=None, parse_cols = \"A,G\")\n",
    "        df.loc[(df['Directory'] == Directory) & (df['Indicator'] == Indicator), 'name'] = myDSvals[1].iloc[6]\n",
    "        df.loc[(df['Directory'] == Directory) & (df['Indicator'] == Indicator), 'description'] = myDSvals[0].iloc[0]\n",
    "    else:\n",
    "        myDSvals = pd.read_excel(\"source/\"+FileName, sheetname='ESTIMATES', skiprows=9, nrows=16 ,  header=None, parse_cols = \"A,F\")\n",
    "        df.loc[(df['Directory'] == Directory) & (df['Indicator'] == Indicator), 'name'] = myDSvals[1].iloc[6]\n",
    "        df.loc[(df['Directory'] == Directory) & (df['Indicator'] == Indicator), 'description'] = myDSvals[0].iloc[0]\n",
    "    \n",
    "    return df\n",
    "    #print(df)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#MAIN Function. Calls the metadata.xslx file and iterate through each file\n",
    "#supports reading multiple files and concatenating them to one dataset as well.\n",
    "def callDataPointFiles(metadata_df):\n",
    "    Ref_Area_List = pd.read_excel('source/countrymetadata.xlsx', parse_cols = \"A:G\")\n",
    "    df = metadata_df\n",
    "    MainStart = time.time()\n",
    "    for i, row in enumerate(metadata_df.values):\n",
    "        start = time.time()\n",
    "        \n",
    "        #date = metadata_df.index[i]\n",
    "        FileName, TypeBY, SEX, Indicator, Directory, name, description, url = row\n",
    "        newFileName = Directory.lower()\n",
    "        newFileName = newFileName.replace(\"ref_area_code\", \"ref_area_code-{}\")\n",
    "        newFileName = newFileName + \".csv\"\n",
    "\n",
    "        #if(TypeBY == \"Age\" or TypeBY == \"AgeYearInterval\"):\n",
    "        if (TypeBY == \"Year\" and Indicator.lower() == \"population\"):\n",
    "        #if (TypeBY == \"Year\" or TypeBY == \"Age\" or TypeBY == \"YearInterval\" or TypeBY == \"AgeYearInterval\"):\n",
    "            print( str(i+1) + ' of '+ str(metadata_df.shape[0]) +' -- ' + FileName)\n",
    "            \n",
    "            #update name & description in metadata file\n",
    "            df = updateMetaData(df, TypeBY, Directory, FileName, Indicator)\n",
    "            \n",
    "            #check if FileName has two or more files. for ex same dimensions with male and female\n",
    "            if(\";\" in FileName):\n",
    "                #if yes then run the method for each files and merge the two dataset.\n",
    "                files = FileName.split(\";\")\n",
    "                ds_allSex = []\n",
    "                #iterate through files then\n",
    "                for file in files:\n",
    "                    if \"_MALE\" in file:\n",
    "                        SEX = \"male\"\n",
    "                    elif \"_FEMALE\" in file:\n",
    "                        SEX = \"female\"\n",
    "                    ds_sex = GetDataFromWorkBookSheets(\"source/\"+file, SEX, Indicator, TypeBY) \n",
    "                    ds_allSex.append(ds_sex)\n",
    "                    \n",
    "                #break\n",
    "                #concat all the sheets and files together as one list\n",
    "                mainds = []\n",
    "                for dss in ds_allSex:\n",
    "                    for dss1 in dss:\n",
    "                        mainds.append(dss1)\n",
    "                dataSet = sortDataSets(mainds, TypeBY, FileName)\n",
    "            else:\n",
    "                ds_sex = GetDataFromWorkBookSheets(\"source/\"+FileName, SEX, Indicator, TypeBY) \n",
    "                dataSet = sortDataSets(ds_sex, TypeBY, FileName)\n",
    "\n",
    "            #put 3 decimal data for age format. Since some files have data for 80+ as 3.4439999 and 3.444 which\n",
    "            #is leading to the duplicate error at validate-ddf\n",
    "#             if (TypeBY == \"Age\"): \n",
    "                #dataSet.loc[dataSet['age'] == \"80+\", Indicator.lower()] = np.round(dataSet[Indicator.lower()],decimals=3)\n",
    "                \n",
    "            dataSet = dataSet.drop_duplicates()\n",
    "\n",
    "            #create files if df is not empty\n",
    "            if not dataSet.empty:\n",
    "                GenerateYearFormatFiles(dataSet, Directory.lower(), newFileName, SEX, Ref_Area_List)\n",
    "                #GenerateYearFormatFiles(dataSet, newFileName, SEX)\n",
    "            else:\n",
    "                print ('File with no data?? Something WRONG?: ' + FileName )\n",
    "            \n",
    "            end = time.time()            \n",
    "            print ('Total Time Taken: ' + str(end-start)) \n",
    "            #break\n",
    "    #break\n",
    "    print ('Total Time For All Files: ' + str(end-MainStart))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generateEntities_Gender():\n",
    "    cdf = pd.DataFrame([], columns=['gender'])\n",
    "    cdf['gender'] = ['male', 'female']\n",
    "    \n",
    "    path = os.path.join(out_dir, 'ddf--entities--gender.csv')\n",
    "    cdf.to_csv(path, index=False)\n",
    "\n",
    "def generateEntities_Freq():\n",
    "    cdf = pd.DataFrame([], columns=['freq'])\n",
    "    cdf['freq'] = ['5yearly']\n",
    "    \n",
    "    path = os.path.join(out_dir, 'ddf--entities--freq.csv')\n",
    "    cdf.to_csv(path, index=False)\n",
    "def generateEntities_Variant():\n",
    "    variant = [x.lower().replace(' ', '').replace('-', '') for x in variants if x != 'NOTES']\n",
    "    \n",
    "    cdf = pd.DataFrame([], columns=['variant'])\n",
    "    cdf['variant'] = variant\n",
    "    \n",
    "    path = os.path.join(out_dir, 'ddf--entities--variant.csv')\n",
    "    cdf.to_csv(path, index=False)\n",
    "def generateEntities_AgeGroups():\n",
    "#     cdf = pd.DataFrame([], columns=['age'])\n",
    "#     cdf['age'] = [ x.replace('-','_').replace('+','plus').replace('Total','total').strip() for x in sorted(set(agegroups))]\n",
    "    \n",
    "#     path = os.path.join(out_dir, 'ddf--entities--age.csv')\n",
    "#     cdf.to_csv(path, index=False)\n",
    "    cdf = pd.DataFrame([], columns=['agebroad','is--agebroad'])\n",
    "    cdf['agebroad'] = [ x.replace('-','_').replace('+','plus').replace('Total','total').strip() for x in sorted(set(ageBroad))]\n",
    "    cdf['is--agebroad'] = 'TRUE'    \n",
    "    path = os.path.join(out_dir, 'ddf--entities--age--agebroad.csv')\n",
    "    cdf.to_csv(path, index=False)\n",
    "    \n",
    "    cdf1 = pd.DataFrame([], columns=['age1yearinterval','is--age1yearinterval'])\n",
    "    #print(age1YrInterval)\n",
    "    cdf1['age1yearinterval'] = [ x.replace('-','_').replace('+','plus').replace('Total','total').strip() for x in sorted(set(age1YrInterval))]\n",
    "    cdf1['is--age1yearinterval'] = 'TRUE'    \n",
    "    path = os.path.join(out_dir, 'ddf--entities--age--age1yearinterval.csv')\n",
    "    cdf1.to_csv(path, index=False)\n",
    "    \n",
    "    cdf2 = pd.DataFrame([], columns=['age5yearinterval','is--age5yearinterval'])\n",
    "    cdf2['age5yearinterval'] = [ x.replace('-','_').replace('+','plus').replace('Total','total').strip() for x in sorted(set(age5YrInterval))]\n",
    "    cdf2['is--age5yearinterval'] = 'TRUE'    \n",
    "    path = os.path.join(out_dir, 'ddf--entities--age--age5yearinterval.csv')\n",
    "    cdf2.to_csv(path, index=False)\n",
    "\n",
    "    \n",
    "def generateEntities_RefAreaCode():\n",
    "    Ref_Area_List = pd.read_excel('source/countrymetadata.xlsx', parse_cols = \"A:G\")\n",
    "    \n",
    "    cdf = pd.DataFrame([], columns=['country', 'name','is--country', 'parent'])\n",
    "    cdf['country'] = Ref_Area_List.loc[Ref_Area_List['is--country'] == 1, 'Code']\n",
    "    cdf['name'] = Ref_Area_List.loc[Ref_Area_List['is--country'] == 1, 'Region']\n",
    "    cdf['parent'] = Ref_Area_List.loc[Ref_Area_List['is--country'] == 1, 'Parent']\n",
    "    cdf['is--country'] = 'TRUE'    \n",
    "    path = os.path.join(out_dir, 'ddf--entities--geo--country.csv')\n",
    "    cdf.to_csv(path, index=False)\n",
    "    \n",
    "    cdf1 = pd.DataFrame([], columns=['region','name','is--region','parent'])\n",
    "    cdf1['region'] = Ref_Area_List.loc[Ref_Area_List['is--region'] == 1, 'Code']\n",
    "    cdf1['name'] = Ref_Area_List.loc[Ref_Area_List['is--region'] == 1, 'Region']\n",
    "    cdf1['parent'] = Ref_Area_List.loc[Ref_Area_List['is--region'] == 1, 'Parent']\n",
    "    cdf1['is--region'] = 'TRUE'\n",
    "    path = os.path.join(out_dir, 'ddf--entities--geo--region.csv')\n",
    "    cdf1.to_csv(path, index=False)\n",
    "    \n",
    "    cdf2 = pd.DataFrame([], columns=['continent','name','is--continent','parent'])\n",
    "    cdf2['continent'] = Ref_Area_List.loc[Ref_Area_List['is--continent'] == 1, 'Code']\n",
    "    cdf2['name'] = Ref_Area_List.loc[Ref_Area_List['is--continent'] == 1, 'Region']\n",
    "    cdf2['parent'] = Ref_Area_List.loc[Ref_Area_List['is--continent'] == 1, 'Parent']\n",
    "    cdf2['is--continent'] = 'TRUE'\n",
    "    path = os.path.join(out_dir, 'ddf--entities--geo--continent.csv')\n",
    "    cdf2.to_csv(path, index=False)\n",
    "    \n",
    "    cdf3 = pd.DataFrame([], columns=['global','name','is--global'])\n",
    "    cdf3['global'] = Ref_Area_List.loc[Ref_Area_List['is--world'] == 1, 'Code']\n",
    "    cdf3['name'] = Ref_Area_List.loc[Ref_Area_List['is--world'] == 1, 'Region']\n",
    "    cdf3['is--global'] = 'TRUE'\n",
    "    path = os.path.join(out_dir, 'ddf--entities--geo--global.csv')\n",
    "    cdf3.to_csv(path, index=False)\n",
    "    \n",
    "def generateConcepts(metadata):\n",
    "    # add all the concepts\n",
    "    concept_name = ['Year', 'Age', 'Gender', 'Freq','Variant' ,'Geo', 'Country', \n",
    "                    'Region', 'Continent', 'Global','AgeBroad', 'Age1YearInterval','Age5YearInterval'\n",
    "                   ,'name', 'parent', 'domain']\n",
    "    \n",
    "    concept_name = concept_name + list(metadata.Indicator.unique())\n",
    "    #print(concept_name)\n",
    "    \n",
    "    # 53 print(len(list(metadata.Indicator.unique())))\n",
    "    \n",
    "    concepts = list(map(to_concept_id, concept_name))\n",
    "    cdf = pd.DataFrame([], columns=['concept', 'concept_type', 'domain', 'name', 'description', 'sourceurl'])\n",
    "    cdf['concept'] = concepts\n",
    "    cdf['concept_type'] = 'measure'\n",
    "    cdf['concept_type'].iloc[1:6] = 'entity_domain'\n",
    "    cdf['concept_type'].iloc[6:13] = 'entity_set'\n",
    "    cdf['concept_type'].iloc[13:16] = 'string'\n",
    "    cdf['domain'].iloc[6:10] = 'geo'\n",
    "    cdf['domain'].iloc[10:13] = 'age'\n",
    "    cdf['concept_type'].iloc[0] = 'time'\n",
    "    \n",
    "#     df = metadata[['Indicator', 'name', 'description', 'sourceurl']].copy()\n",
    "#     #df.rename(columns={'Indicator':'concept'})\n",
    "#     df = df.drop_duplicates()\n",
    "#     x1 = cdf.set_index('concept')['name']\n",
    "#     print(df)\n",
    "#     x2 = df.set_index('Indicator')['name']\n",
    "    \n",
    "#     print(x1.update(x2))\n",
    "    \n",
    "#     print(cdf.update(df.set_index('concept')))\n",
    "    #print(pd.merge(cdf, df.rename(columns={'Indicator':'concept'}), how='left', on='concept'))\n",
    "    \n",
    "    #cdf['name'].iloc[16:] = list(metadata.name)\n",
    "    #cdf['description'].iloc[16:] = list(metadata.description)\n",
    "    \n",
    "    path = os.path.join(out_dir, 'ddf--concepts.csv')\n",
    "    cdf.to_csv(path, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 79 -- WPP2015_POP_F01_1_TOTAL_POPULATION_BOTH_SEXES.XLS\n",
      "Total Time Taken: 6.2082200050354\n",
      "2 of 79 -- WPP2015_POP_F01_2_TOTAL_POPULATION_MALE.XLS;WPP2015_POP_F01_3_TOTAL_POPULATION_FEMALE.XLS\n",
      "Total Time Taken: 10.600558996200562\n",
      "Total Time For All Files: 16.809096097946167\n",
      "                                 Indicator  \\\n",
      "0                               Population   \n",
      "1                               Population   \n",
      "2                SexRatio_MalePer100Female   \n",
      "3                    MedianAgeOfPopulation   \n",
      "4                 PopulationDensityPerSqKm   \n",
      "5                      DependencyRatio1564   \n",
      "6                      DependencyRatio2064   \n",
      "7                      DependencyRatio2069   \n",
      "8                      DependencyRatio2564   \n",
      "9                      DependencyRatio2569   \n",
      "10                ChildDependencyRatio1564   \n",
      "11                ChildDependencyRatio2064   \n",
      "12                ChildDependencyRatio2069   \n",
      "13                ChildDependencyRatio2564   \n",
      "14                ChildDependencyRatio2569   \n",
      "15               OldAgeDependencyRatio1564   \n",
      "16               OldAgeDependencyRatio2064   \n",
      "17               OldAgeDependencyRatio2069   \n",
      "18               OldAgeDependencyRatio2564   \n",
      "19               OldAgeDependencyRatio2569   \n",
      "20                 PotentialSupport1664_65   \n",
      "21                 PotentialSupport2064_65   \n",
      "22                 PotentialSupport2069_65   \n",
      "23                 PotentialSupport2564_65   \n",
      "24                 PotentialSupport2569_70   \n",
      "25                       NoOfBirthByMother   \n",
      "26               FertilityRatePer1000Women   \n",
      "27                              Population   \n",
      "33                             TotalDeaths   \n",
      "36                   PercentageTotalDeaths   \n",
      "38                             SurvivorAge   \n",
      "40                          LifeExpectancy   \n",
      "42               PercentageTotalPopulation   \n",
      "45           FeminityRato_FemalePer100Male   \n",
      "46                               NoOfBirth   \n",
      "47                  SexRatio_MalePerFemale   \n",
      "48                  BirthPer1000Population   \n",
      "49                          TotalFertility   \n",
      "50                     NetReporductionRate   \n",
      "51                  MeanAgeForChildBearing   \n",
      "52              NetMigrationRatePer1000Pop   \n",
      "53                     NetNumberOfMigrants   \n",
      "54         InfantMortalityPer1000livebirth   \n",
      "55         Under5MortalityPer1000livebirth   \n",
      "56         CrudeDeathRatePer1000Population   \n",
      "59                   LifeExpectancyAtBirth   \n",
      "61        Under40MortalityPer1000livebirth   \n",
      "63        Under60MortalityPer1000livebirth   \n",
      "65         Mortality15to50Per1000aliveAt15   \n",
      "67         Mortality15to60Per1000aliveAt15   \n",
      "69                      LifeExpectancyAt15   \n",
      "71                      LifeExpectancyAt60   \n",
      "73                      LifeExpectancyAt80   \n",
      "75                    PopulationGrowthRate   \n",
      "76  RateOfNaturalIncreasePer1000Population   \n",
      "\n",
      "                                                 name  \\\n",
      "0   Total population, both sexes combined, as of 1...   \n",
      "1           Male population, as of 1 July (thousands)   \n",
      "2                                                       \n",
      "3                                                       \n",
      "4                                                       \n",
      "5                                                       \n",
      "6                                                       \n",
      "7                                                       \n",
      "8                                                       \n",
      "9                                                       \n",
      "10                                                      \n",
      "11                                                      \n",
      "12                                                      \n",
      "13                                                      \n",
      "14                                                      \n",
      "15                                                      \n",
      "16                                                      \n",
      "17                                                      \n",
      "18                                                      \n",
      "19                                                      \n",
      "20                                                      \n",
      "21                                                      \n",
      "22                                                      \n",
      "23                                                      \n",
      "24                                                      \n",
      "25                                                      \n",
      "26                                                      \n",
      "27                                                      \n",
      "33                                                      \n",
      "36                                                      \n",
      "38                                                      \n",
      "40                                                      \n",
      "42                                                      \n",
      "45                                                      \n",
      "46                                                      \n",
      "47                                                      \n",
      "48                                                      \n",
      "49                                                      \n",
      "50                                                      \n",
      "51                                                      \n",
      "52                                                      \n",
      "53                                                      \n",
      "54                                                      \n",
      "55                                                      \n",
      "56                                                      \n",
      "59                                                      \n",
      "61                                                      \n",
      "63                                                      \n",
      "65                                                      \n",
      "67                                                      \n",
      "69                                                      \n",
      "71                                                      \n",
      "73                                                      \n",
      "75                                                      \n",
      "76                                                      \n",
      "\n",
      "                                          description  \\\n",
      "0   File POP/1-1: Total population (both sexes com...   \n",
      "1   File POP/1-2: Male population by major area, r...   \n",
      "2                                                       \n",
      "3                                                       \n",
      "4                                                       \n",
      "5                                                       \n",
      "6                                                       \n",
      "7                                                       \n",
      "8                                                       \n",
      "9                                                       \n",
      "10                                                      \n",
      "11                                                      \n",
      "12                                                      \n",
      "13                                                      \n",
      "14                                                      \n",
      "15                                                      \n",
      "16                                                      \n",
      "17                                                      \n",
      "18                                                      \n",
      "19                                                      \n",
      "20                                                      \n",
      "21                                                      \n",
      "22                                                      \n",
      "23                                                      \n",
      "24                                                      \n",
      "25                                                      \n",
      "26                                                      \n",
      "27                                                      \n",
      "33                                                      \n",
      "36                                                      \n",
      "38                                                      \n",
      "40                                                      \n",
      "42                                                      \n",
      "45                                                      \n",
      "46                                                      \n",
      "47                                                      \n",
      "48                                                      \n",
      "49                                                      \n",
      "50                                                      \n",
      "51                                                      \n",
      "52                                                      \n",
      "53                                                      \n",
      "54                                                      \n",
      "55                                                      \n",
      "56                                                      \n",
      "59                                                      \n",
      "61                                                      \n",
      "63                                                      \n",
      "65                                                      \n",
      "67                                                      \n",
      "69                                                      \n",
      "71                                                      \n",
      "73                                                      \n",
      "75                                                      \n",
      "76                                                      \n",
      "\n",
      "                                            sourceurl  \n",
      "0   https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "1   https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "2   https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "3   https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "4   https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "5   https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "6   https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "7   https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "8   https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "9   https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "10  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "11  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "12  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "13  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "14  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "15  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "16  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "17  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "18  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "19  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "20  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "21  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "22  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "23  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "24  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "25  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "26  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "27  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "33  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "36  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "38  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "40  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "42  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "45  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "46  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "47  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "48  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "49  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "50  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "51  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "52  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "53  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "54  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "55  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "56  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "59  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "61  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "63  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "65  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "67  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "69  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "71  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "73  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "75  https://esa.un.org/unpd/wpp/Download/Standard/...  \n",
      "76  https://esa.un.org/unpd/wpp/Download/Standard/...  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-302-cf21a35f4b28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#print (metadata_df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#generate concepts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgenerateConcepts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#generate variants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-301-5d770c95057a>\u001b[0m in \u001b[0;36mgenerateConcepts\u001b[0;34m(metadata)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Indicator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'concept'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harpalshergill/anaconda/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m         \"\"\"\n\u001b[0;32m-> 1668\u001b[0;31m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1669\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harpalshergill/anaconda/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex_like\u001b[0;34m(self, other, method, copy, limit, tolerance)\u001b[0m\n\u001b[1;32m   1842\u001b[0m                                        tolerance=tolerance)\n\u001b[1;32m   1843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1844\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harpalshergill/anaconda/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, index, **kwargs)\u001b[0m\n\u001b[1;32m   2285\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reindex'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2289\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fillna'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harpalshergill/anaconda/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0;31m# perform the reindex on the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         return self._reindex_axes(axes, level, limit, tolerance, method,\n\u001b[0;32m-> 2229\u001b[0;31m                                   fill_value, copy).__finalize__(self)\n\u001b[0m\u001b[1;32m   2230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m     def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,\n",
      "\u001b[0;32m/Users/harpalshergill/anaconda/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   2245\u001b[0m             obj = obj._reindex_with_indexers({axis: [new_index, indexer]},\n\u001b[1;32m   2246\u001b[0m                                              \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2247\u001b[0;31m                                              copy=copy, allow_dups=False)\n\u001b[0m\u001b[1;32m   2248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2249\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harpalshergill/anaconda/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   2339\u001b[0m                                                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2340\u001b[0m                                                 \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_dups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2341\u001b[0;31m                                                 copy=copy)\n\u001b[0m\u001b[1;32m   2342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harpalshergill/anaconda/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   3584\u001b[0m         \u001b[0;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3586\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_reindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harpalshergill/anaconda/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36m_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   2291\u001b[0m         \u001b[0;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2293\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2295\u001b[0m     def reindex(self, target, method=None, level=None, limit=None,\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "metadata_df = pd.read_excel('source/metadata.xlsx', parse_cols = \"A:E\")\n",
    "metadata_df['name'] = ''\n",
    "metadata_df['description'] = ''\n",
    "metadata_df['sourceurl'] = 'https://esa.un.org/unpd/wpp/Download/Standard/Population/'\n",
    "#print (metadata_df)\n",
    "metadata_df = callDataPointFiles(metadata_df)\n",
    "#print (metadata_df)\n",
    "#generate concepts\n",
    "generateConcepts(metadata_df)\n",
    "\n",
    "#generate variants\n",
    "generateEntities_Variant()\n",
    "\n",
    "#generate countries/world/regions\n",
    "generateEntities_RefAreaCode()\n",
    "\n",
    "#generate age groups\n",
    "generateEntities_AgeGroups()\n",
    "\n",
    "#generate gender\n",
    "generateEntities_Gender()\n",
    "\n",
    "#generate freq\n",
    "generateEntities_Freq()\n",
    "\n",
    "#print (concepts)\n",
    "\n",
    "# add year interval information for freqency/\n",
    "# split ref_area_code into World/Continent/Region/Country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
