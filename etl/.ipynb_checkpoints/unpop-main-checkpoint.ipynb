{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "#from xlrd import open_workbook\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from ddf_utils.str import to_concept_id\n",
    "from ddf_utils.datapackage import create_datapackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#out_dir = '../../'\n",
    "out_dir = '../'\n",
    "\n",
    "# global variables to build data for concepts and entities\n",
    "variants = []\n",
    "agegroups = []\n",
    "age1YrInterval = []\n",
    "ageBroad = []\n",
    "age5YrInterval = []\n",
    "ref_AreaCode = []\n",
    "\n",
    "metadata_df = pd.read_excel('source/metadata.xlsx', sheetname= 'metadata', parse_cols = \"A:G\")\n",
    "metadata_df['name'] = ''\n",
    "metadata_df['description'] = ''\n",
    "metadata_df['sourceurl'] = 'https://esa.un.org/unpd/wpp/Download/Standard/Population/'\n",
    "\n",
    "Ref_Area_List = pd.read_excel('source/countrymetadata.xlsx', parse_cols = \"A:G\")\n",
    "NewFormatInfo = pd.read_excel ('source/metadata.xlsx', sheetname= 'DemographyFormat', parse_cols = \"A:C\")\n",
    "BroadAgeMap = pd.read_excel ('source/metadata.xlsx', sheetname= 'BroadAgeMap', parse_cols = \"A:B\")\n",
    "DependencyMap = pd.read_excel('source/metadata.xlsx', sheetname= 'DependencyFormat', parse_cols = \"A:C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#method to read files in a folder...\n",
    "#onlyfiles = [f for f in listdir('source/byYearInterval') if isfile(join('source/byYearInterval', f))]\n",
    "#onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to create directory if it does not exist\n",
    "def createDirectory(Directory):\n",
    "    if not os.path.exists('../'+Directory.lower()):\n",
    "        os.makedirs('../'+Directory.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to generate files from the data points.\n",
    "def GenerateYearFormatFiles(ds_all, Directory, FileNameWithPath, gender, Ref_Area_List):\n",
    "    # drop gender column is both sex or NA.\n",
    "    if (gender.upper() == 'TOTAL') or (gender.upper() == \"NA\"):\n",
    "        ds_all = ds_all.drop('gender', axis=1)\n",
    "\n",
    "    # group data by ref_area_code as files are generated by this grouping\n",
    "    for geo, idxs in ds_all.groupby(by='ref_area_code').groups.items():\n",
    "        myDS = ds_all.ix[idxs]\n",
    "        #change the age dimenstion based on age group in file\n",
    "        if(\"agebroad\" in Directory.lower()):\n",
    "            myDS = myDS.rename(columns={\n",
    "                'age': 'agebroad'\n",
    "            })\n",
    "        elif(\"age1yearinterval\" in Directory.lower()):\n",
    "            myDS = myDS.rename(columns={\n",
    "                'age': 'age1yearinterval'\n",
    "            })\n",
    "        elif(\"age5yearinterval\" in Directory.lower()):\n",
    "            myDS = myDS.rename(columns={\n",
    "                'age': 'age5yearinterval'\n",
    "            })\n",
    "        \n",
    "        \n",
    "        data = Ref_Area_List.loc[Ref_Area_List['Code'] == geo]\n",
    "        # update the directory and file names based on geo in country, continent, region or global\n",
    "        if(data.iloc[0]['is--world'] == 1):\n",
    "            NewDirectory = Directory.replace('ref_area_code','global')\n",
    "            NewFileNameWithPath = FileNameWithPath.replace('ref_area_code','global')\n",
    "            myDS = myDS.rename(columns={\n",
    "                'ref_area_code': 'global'\n",
    "            })\n",
    "        elif (data.iloc[0]['is--region'] == 1):\n",
    "            NewDirectory = Directory.replace('ref_area_code','region')\n",
    "            NewFileNameWithPath = FileNameWithPath.replace('ref_area_code','region')\n",
    "            myDS = myDS.rename(columns={\n",
    "                'ref_area_code': 'region'\n",
    "            })\n",
    "        elif (data.iloc[0]['is--continent'] == 1):\n",
    "            NewDirectory = Directory.replace('ref_area_code','continent')\n",
    "            NewFileNameWithPath = FileNameWithPath.replace('ref_area_code','continent')\n",
    "            myDS = myDS.rename(columns={\n",
    "                'ref_area_code': 'continent'\n",
    "            })\n",
    "        elif (data.iloc[0]['is--country'] == 1):\n",
    "            NewDirectory = Directory.replace('ref_area_code','country')\n",
    "            NewFileNameWithPath = FileNameWithPath.replace('ref_area_code','country')\n",
    "            myDS = myDS.rename(columns={\n",
    "                'ref_area_code': 'country'\n",
    "            })\n",
    "        \n",
    "        createDirectory(NewDirectory)\n",
    "        path = os.path.join(out_dir,NewDirectory+'/'+NewFileNameWithPath.format(geo))\n",
    "        \n",
    "        myDS.to_csv(path, index=False, float_format='%.15g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function for interpolated dataset\n",
    "def load_Files_new(source, variant, gender, TypeBy):\n",
    "    #load file using pandas\n",
    "    data = pd.read_excel(source, sheetname= variant, skiprows=16, na_values='…')\n",
    "    data = data.drop(['Index', 'Notes'], axis = 1)\n",
    "    \n",
    "    if(gender.lower() == \"male\"):\n",
    "        data['Gender'] = 'male'\n",
    "    elif(gender.lower() == \"female\"):\n",
    "        data['Gender'] = 'female'\n",
    "    \n",
    "    #rename country column and country code column\n",
    "    data = data.rename(columns={\n",
    "        #'Major area, region, country or area *': 'Ref_Area',\n",
    "        'Country code': 'Ref_Area_Code',\n",
    "        'Reference date (1 January - 31 December)': 'Year'\n",
    "    })\n",
    "    \n",
    "    #update columns name from NewFormatInfo file\n",
    "    for i, row in enumerate(NewFormatInfo.values):\n",
    "        IndicatorInitial, IndicatorDest, DestFolder = row\n",
    "        if(\";\" in IndicatorInitial):\n",
    "            if(IndicatorDest == \"TotalDeaths\"):\n",
    "                data = data.rename(columns={\n",
    "                        \"Male deaths (thousands)\" : \"TotalDeaths_Male\",\n",
    "                        \"Female deaths (thousands)\" : \"TotalDeaths_Female\"\n",
    "                    })\n",
    "            elif(IndicatorDest == \"LifeExpectancyAtBirth\"):\n",
    "                data = data.rename(columns={\n",
    "                        \"Life expectancy at birth, males (years)\" : \"LifeExpectancyAtBirth_Male\",\n",
    "                        \"Life expectancy at birth, females (years)\" : \"LifeExpectancyAtBirth_Female\"\n",
    "                    })\n",
    "        else:\n",
    "            data = data.rename(columns={IndicatorInitial : IndicatorDest})\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to load files, skip the first 16 lines and specify na values as '...'\n",
    "def load_Files(source, variant, gender, TypeBy):\n",
    "    #load file using pandas\n",
    "    data = pd.read_excel(source, sheetname= variant, skiprows=16, na_values='…')\n",
    "    data = data.drop(['Index', 'Notes'], axis = 1)\n",
    "    \n",
    "    #rename country column and country code column\n",
    "    data = data.rename(columns={\n",
    "        #'Major area, region, country or area *': 'Ref_Area',\n",
    "        'Country code': 'Ref_Area_Code'\n",
    "    })\n",
    "    #year column is present in Age Type sheets\n",
    "    if (TypeBy == \"Age\"):\n",
    "        data = data.rename(columns={\n",
    "        'Reference date (as of 1 July)': 'Year'\n",
    "    })\n",
    "    #insert Gender column\n",
    "    data.insert(3, 'Gender', gender)\n",
    "    if (TypeBy == \"YearInterval\"):\n",
    "        data.insert(3, 'Freq', '5yearly')\n",
    "    elif (TypeBy == \"AgeYearInterval\"):\n",
    "        data = data.rename(columns={\n",
    "        'Period': 'Year'\n",
    "        })\n",
    "        #get first year in yyyy-yyyy time period\n",
    "        data['Year'] = data['Year'].str[:4] \n",
    "        data.insert(3, 'Freq', '5yearly')\n",
    "\n",
    "    #update teh AreaCode entity list\n",
    "    global ref_AreaCode\n",
    "    ref_AreaCode = ref_AreaCode + list(set(data['Ref_Area_Code']) - set(ref_AreaCode))\n",
    "\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetDataFromWorkBookSheets(source, gender, indicator, TypeBy):\n",
    "    all_variants = []\n",
    "\n",
    "    #pandas excel file fun.\n",
    "    wbb = pd.ExcelFile(source)\n",
    "    \n",
    "    #add variant concepts to global variable for entity set\n",
    "    global variants\n",
    "    variants = variants + list(set(wbb.sheet_names) - set(variants))\n",
    "    \n",
    "    #iterate through each SHEET except \"NOTES\"\n",
    "    for sheetName in wbb.sheet_names:\n",
    "        if(sheetName == 'NOTES'):\n",
    "            #ignore NOTES sheet since we are not collecting metadata yet\n",
    "            continue\n",
    "        else:\n",
    "            #first load the files\n",
    "            mydata = load_Files(source, sheetName, gender, TypeBy)\n",
    "#             print(mydata.head(1))\n",
    "#             mydata = mydata.drop(['Ref_Area'], axis=1)\n",
    "#             #based on File format type apply the index and set the column value\n",
    "            if (TypeBy == \"Age\"):\n",
    "                mydata = mydata.set_index(['Ref_Area_Code','Year','Variant','Gender'])\n",
    "                mydata.columns.name = 'Age'\n",
    "            elif (TypeBy == \"Year\"):\n",
    "                mydata = mydata.set_index(['Ref_Area_Code','Variant', 'Gender'])\n",
    "                mydata.columns.name = 'Year'\n",
    "            elif (TypeBy == \"YearInterval\"):\n",
    "                mydata = mydata.set_index(['Ref_Area_Code','Variant', 'Gender', 'Freq'])\n",
    "                mydata.columns.name = 'Year'\n",
    "            elif (TypeBy == \"AgeYearInterval\"):\n",
    "                mydata = mydata.set_index(['Ref_Area_Code','Year','Variant','Gender', 'Freq'])\n",
    "                mydata.columns.name = 'Age'\n",
    "            \n",
    "            mydata = mydata.stack().reset_index().rename(columns={0:indicator})\n",
    "            all_variants.append(mydata)\n",
    "            \n",
    "            #break\n",
    "    return all_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataFiles_simple(ds_all, Directory):\n",
    "    #print(Directory)\n",
    "    newFileName1 = Directory.lower()\n",
    "    newFileName1 = newFileName1.replace(\"ref_area_code\", \"ref_area_code-{}\")\n",
    "    newFileName1 = newFileName1 + \".csv\"\n",
    "    \n",
    "    # group data by ref_area_code as files are generated by this grouping\n",
    "    for geo, idxs in ds_all.groupby(by='ref_area_code').groups.items():\n",
    "        myDS = ds_all.ix[idxs]\n",
    "        \n",
    "        data = Ref_Area_List.loc[Ref_Area_List['Code'] == geo]\n",
    "        # update the directory and file names based on geo in country, continent, region or global\n",
    "        if(data.iloc[0]['is--world'] == 1):\n",
    "            NewDirectory = Directory.replace('ref_area_code','global')\n",
    "            newFileName = newFileName1.replace('ref_area_code','global')\n",
    "            myDS = myDS.rename(columns={\n",
    "                'ref_area_code': 'global'\n",
    "            })\n",
    "        elif (data.iloc[0]['is--region'] == 1):\n",
    "            NewDirectory = Directory.replace('ref_area_code','region')\n",
    "            newFileName = newFileName1.replace('ref_area_code','region')\n",
    "            myDS = myDS.rename(columns={\n",
    "                'ref_area_code': 'region'\n",
    "            })\n",
    "        elif (data.iloc[0]['is--continent'] == 1):\n",
    "            NewDirectory = Directory.replace('ref_area_code','continent')\n",
    "            newFileName = newFileName1.replace('ref_area_code','continent')\n",
    "            myDS = myDS.rename(columns={\n",
    "                'ref_area_code': 'continent'\n",
    "            })\n",
    "        elif (data.iloc[0]['is--country'] == 1):\n",
    "            NewDirectory = Directory.replace('ref_area_code','country')\n",
    "            newFileName = newFileName1.replace('ref_area_code','country')\n",
    "            myDS = myDS.rename(columns={\n",
    "                'ref_area_code': 'country'\n",
    "            })\n",
    "        createDirectory(NewDirectory)\n",
    "        path = os.path.join(out_dir,NewDirectory+'/'+newFileName.format(geo))\n",
    "\n",
    "        myDS.to_csv(path, index=False, float_format='%.15g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#method to sort the file with refArea, Year, Variant, Gender\n",
    "def sortDataSets(dsSet_all, TypeBy, FileName):\n",
    "    dataSet = pd.concat(dsSet_all, ignore_index=True) \n",
    "    dataSet.columns = list(map(to_concept_id, dataSet.columns))\n",
    "    \n",
    "    #remove the blank space from variants\n",
    "    dataSet['variant'] = [ x.lower().replace(' ', '_').replace('-','_') for x in dataSet['variant']]\n",
    "        \n",
    "    #global agegroups\n",
    "    global age1YrInterval\n",
    "    global ageBroad\n",
    "    global age5YrInterval\n",
    "    \n",
    "    if (TypeBy == \"Age\"): \n",
    "        #update the global variables for 3 age groups with any new values\n",
    "        if(\"broad_age\" in FileName.lower()):\n",
    "            ageBroad = ageBroad + list(set(dataSet['age'].unique()) - set(ageBroad))\n",
    "        elif(\"age_annual\" in FileName.lower()):\n",
    "            age1YrInterval = age1YrInterval + list(set(dataSet['age'].unique()) - set(age1YrInterval))\n",
    "        elif(\"_age_\" in FileName.lower()):\n",
    "            age5YrInterval = age5YrInterval + list(set(dataSet['age'].unique()) - set(age5YrInterval))\n",
    "        #replace - and + and higher case char to _, plus and lower case respectively\n",
    "        dataSet['age'] = [ x.replace('-','_').replace('+','plus').replace('Total','total').strip() for x in dataSet['age']]\n",
    "        \n",
    "        dataSet['age'] = dataSet['age'].astype('category', categories=list(dataSet['age'].unique()), ordered=True)\n",
    "        dataSet = dataSet.sort_values(by=['ref_area_code', 'year','age','variant', 'gender'])\n",
    "    elif (TypeBy == \"Year\"):\n",
    "        dataSet = dataSet.sort_values(by=['ref_area_code', 'year','variant', 'gender'])\n",
    "    elif (TypeBy == \"YearInterval\"):\n",
    "        dataSet['year'] = dataSet['year'].str[:4]\n",
    "        dataSet = dataSet.sort_values(by=['ref_area_code', 'year','variant', 'gender', 'freq'])\n",
    "    elif (TypeBy == \"AgeYearInterval\"):\n",
    "        #update the global variables for 3 age groups with any new values\n",
    "        if(\"broad_age\" in FileName.lower()):\n",
    "            ageBroad = ageBroad + list(set(dataSet['age'].unique()) - set(ageBroad))\n",
    "        elif(\"age_annual\" in FileName.lower()):\n",
    "            age1YrInterval = age1YrInterval + list(set(dataSet['age'].unique()) - set(age1YrInterval))\n",
    "        elif(\"_age_\" in FileName.lower()):\n",
    "            age5YrInterval = age5YrInterval + list(set(dataSet['age'].unique()) - set(age5YrInterval))\n",
    "        dataSet['age'] = [ x.replace('-','_').replace('+','plus').replace('Total','total').strip() for x in dataSet['age']]\n",
    "        \n",
    "        dataSet['age'] = dataSet['age'].astype('category', categories=list(dataSet['age'].unique()), ordered=True)\n",
    "        dataSet = dataSet.sort_values(by=['ref_area_code', 'year','age','variant', 'gender', 'freq'])\n",
    "   \n",
    "    return dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hardcode the indicator's Note and Descriptions values for indicators which shares multiple files. \n",
    "def updateConceptDF(df, myDSvals, Indicator):\n",
    "    if(Indicator.lower() == \"population\"):\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'name'] = 'population by age group (thousands)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'description'] = 'population by age group, major area, region and country, 1950-2100 (thousands)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'sourceurl'] = 'https://esa.un.org/unpd/wpp/DVD/'\n",
    "    elif(Indicator.lower() == \"lifeexpectancy\"):\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'name'] = 'life expectancy, e(x), at exact age x (years)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'description'] = 'life expectancy at exact age, e(x), by major area, region and country, 1950-2100'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'sourceurl'] = 'https://esa.un.org/unpd/wpp/DVD/'\n",
    "    elif(Indicator.lower() == \"lifeexpectancyat15\"):\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'name'] = 'life expectancy at age 15 (years)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'description'] = 'life expectancy at age 15 by major area, region and country, 1950-2100 (years)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'sourceurl'] = 'https://esa.un.org/unpd/wpp/DVD/'\n",
    "    elif(Indicator.lower() == \"lifeexpectancyat60\"):\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'name'] = 'life expectancy at age 60 (years)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'description'] = 'life expectancy at age 60 by major area, region and country, 1950-2100 (years)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'sourceurl'] = 'https://esa.un.org/unpd/wpp/DVD/'\n",
    "    elif(Indicator.lower() == \"lifeexpectancyat80\"):\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'name'] = 'life expectancy at age 80 (years)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'description'] = 'life expectancy at age 80 by major area, region and country, 1950-2100 (years)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'sourceurl'] = 'https://esa.un.org/unpd/wpp/DVD/'\n",
    "    elif(Indicator.lower() == \"lifeexpectancyatbirth\"):\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'name'] = 'life expectancy at birth (years)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'description'] = 'life expectancy at birth by major area, region and country, 1950-2100 (years)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'sourceurl'] = 'https://esa.un.org/unpd/wpp/DVD/'\n",
    "    elif(Indicator.lower() == \"mortality15to50per1000aliveat15\"):\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'name'] = 'adult mortality between age 15 and 50, 35q15 (deaths under age 50 per 1,000 alive at age 15)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'description'] = 'probability of dying between the ages of 15 and 50 years by major area, region and country, 1950-2100 (deaths under age 50 per 1,000 alive at age 15)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'sourceurl'] = 'https://esa.un.org/unpd/wpp/DVD/'\n",
    "    elif(Indicator.lower() == \"mortality15to60per1000aliveat15\"):\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'name'] = 'adult mortality between age 15 and 60, 45q15 (deaths under age 60 per 1,000 alive at age 15)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'description'] = 'probability of dying between the ages of 15 and 60 years by major area, region and country, 1950-2100 (deaths under age 60 per 1,000 alive at age 15)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'sourceurl'] = 'https://esa.un.org/unpd/wpp/DVD/'\n",
    "    elif(Indicator.lower() == \"percentagetotaldeaths\"):\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'name'] = 'Percentage of deaths by age group (per 100 (male/female/all) total population)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'description'] = 'Percentage of deaths by age group, major area, region and country, 1950-2100'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'sourceurl'] = 'https://esa.un.org/unpd/wpp/DVD/'\n",
    "    elif(Indicator.lower() == \"percentagetotalpopulation\"):\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'name'] = 'Percentage of population by age group (per 100 (male/female/all) total population)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'description'] = 'Percentage population by age group, major area, region and country, 1950-2100'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'sourceurl'] = 'https://esa.un.org/unpd/wpp/DVD/'\n",
    "    elif(Indicator.lower() == \"sexratio_maleper100female\"):\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'name'] = 'Sex ratio by age group (males per 100 females by age group)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'description'] = 'Sex ratio by age group, major area, region and country, 1950-2100 (males per 100 females by age group)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'sourceurl'] = 'https://esa.un.org/unpd/wpp/DVD/'\n",
    "    elif(Indicator.lower() == \"survivorage\"):\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'name'] = 'life table survivors, l(x), at exact age (x)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'description'] = 'life table survivors at exact age, l(x), by major area, region and country, 1950-2100'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'sourceurl'] = 'https://esa.un.org/unpd/wpp/DVD/'\n",
    "    elif(Indicator.lower() == \"totaldeaths\"):\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'name'] = 'Number of deaths (thousands)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'description'] = 'deaths, by major area, region and country, 1950-2100 (thousands)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'sourceurl'] = 'https://esa.un.org/unpd/wpp/DVD/'\n",
    "    elif(Indicator.lower() == \"under40mortalityper1000livebirth\"):\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'name'] = 'under-forty mortality, 40q0 (deaths under age 40 per 1,000 live births)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'description'] = 'probability of dying between birth and the age of 40 years by major area, region and country, 1950-2100 (deaths under age 40 per 1,000 live births)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'sourceurl'] = 'https://esa.un.org/unpd/wpp/DVD/'\n",
    "    elif(Indicator.lower() == \"under60mortalityper1000livebirth\"):\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'name'] = 'under-sixty mortality, 60q0 (deaths under age 60 per 1,000 live births)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'description'] = 'probability of dying between birth and the age of 60 years by major area, region and country, 1950-2100 (deaths under age 60 per 1,000 live births)'\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'sourceurl'] = 'https://esa.un.org/unpd/wpp/DVD/'\n",
    "    else:\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'name'] = myDSvals[1].iloc[6]\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'description'] = myDSvals[0].iloc[0]\n",
    "        df.loc[(df['concept'] == Indicator.lower()), 'sourceurl'] = 'https://esa.un.org/unpd/wpp/DVD/'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method to have concept dataframe updated with note and descriptions for each measure.\n",
    "def updateMetaData(df, TypeBY, Directory, FileName, Indicator):\n",
    "    if(\";\" in FileName):\n",
    "        #then get first filename\n",
    "        files = FileName.split(\";\")\n",
    "        FileName = files[0]\n",
    "    \n",
    "    #read the excel file to get indicator and description\n",
    "    if(TypeBY == 'Age'or TypeBY == \"AgeYearInterval\"):\n",
    "        myDSvals = pd.read_excel(\"source/\"+FileName, sheetname='ESTIMATES', skiprows=9, nrows=16 ,  header=None, parse_cols = \"A,G\")\n",
    "        df = updateConceptDF(df, myDSvals, Indicator)\n",
    "    else:\n",
    "        myDSvals = pd.read_excel(\"source/\"+FileName, sheetname='ESTIMATES', skiprows=9, nrows=16 ,  header=None, parse_cols = \"A,F\")\n",
    "        df = updateConceptDF(df, myDSvals, Indicator)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#funtion for interpolated datset\n",
    "def createDataFiles_new(ds):\n",
    "    for i, row in enumerate(NewFormatInfo.values):\n",
    "        IndicatorInitial, IndicatorDest, DestFolder = row\n",
    "        print('creating files for: ' + IndicatorDest)\n",
    "        ds.columns = list(map(to_concept_id, ds.columns))\n",
    "        \n",
    "        ds['variant'] = [ x.lower().replace(' ', '_').replace('-','_') for x in ds['variant']]\n",
    "    \n",
    "        \n",
    "        Directory = DestFolder.lower().replace('newformat', IndicatorDest.lower())\n",
    "        #print(Directory)\n",
    "        newFileName1 = Directory.lower()\n",
    "        newFileName1 = newFileName1.replace(\"ref_area_code\", \"ref_area_code-{}\")\n",
    "        newFileName1 = newFileName1 + \".csv\"\n",
    "        \n",
    "        #ds_all = ds[['variant','ref_area_code','year', IndicatorInitial]].copy()\n",
    "        \n",
    "        #if IndicatorInitial contain ;\n",
    "        if(\";\" in IndicatorInitial):\n",
    "            if(IndicatorDest.lower() == \"totaldeaths\"):\n",
    "                ds_all_1 = ds[['variant','ref_area_code','year','totaldeaths_male']].copy()\n",
    "                ds_all_1.columns = ['variant','ref_area_code','year','totaldeaths']\n",
    "                ds_all_1['gender'] = 'male'\n",
    "                \n",
    "                ds_all_2 = ds[['variant','ref_area_code','year','totaldeaths_female']].copy()\n",
    "                ds_all_2.columns = ['variant','ref_area_code','year','totaldeaths']\n",
    "                ds_all_2['gender'] = 'female'\n",
    "                \n",
    "                frames = [ds_all_1, ds_all_2]\n",
    "                ds_all = pd.concat(frames, ignore_index=True) \n",
    "                ds_all = ds_all.drop_duplicates()\n",
    "            elif(IndicatorDest.lower() == \"lifeexpectancyatbirth\"):\n",
    "                ds_all_1 = ds[['variant','ref_area_code','year','lifeexpectancyatbirth_male' ]].copy()\n",
    "                ds_all_1.columns = ['variant','ref_area_code','year','lifeexpectancyatbirth']\n",
    "                ds_all_1['gender'] = 'male'\n",
    "                ds_all_2 = ds[['variant','ref_area_code','year','lifeexpectancyatbirth_female' ]].copy()\n",
    "                ds_all_2.columns = ['variant','ref_area_code','year','lifeexpectancyatbirth']\n",
    "                ds_all_2['gender'] = 'female'\n",
    "                frames = [ds_all_1, ds_all_2]\n",
    "                ds_all = pd.concat(frames, ignore_index=True) \n",
    "                ds_all = ds_all.drop_duplicates()\n",
    "        else:\n",
    "            ds_all = ds[['variant','ref_area_code','year', IndicatorDest.lower()]].copy()\n",
    "        \n",
    "#         print(ds_all.columns)\n",
    "#         print(ds_all.head(1))\n",
    "        # group data by ref_area_code as files are generated by this grouping\n",
    "        for geo, idxs in ds_all.groupby(by='ref_area_code').groups.items():\n",
    "            myDS = ds_all.ix[idxs]\n",
    "\n",
    "            data = Ref_Area_List.loc[Ref_Area_List['Code'] == geo]\n",
    "            # update the directory and file names based on geo in country, continent, region or global\n",
    "            if(data.iloc[0]['is--world'] == 1):\n",
    "                NewDirectory = Directory.replace('ref_area_code','global')\n",
    "                newFileName = newFileName1.replace('ref_area_code','global')\n",
    "                myDS = myDS.rename(columns={\n",
    "                    'ref_area_code': 'global'\n",
    "                })\n",
    "            elif (data.iloc[0]['is--region'] == 1):\n",
    "                NewDirectory = Directory.replace('ref_area_code','region')\n",
    "                newFileName = newFileName1.replace('ref_area_code','region')\n",
    "                myDS = myDS.rename(columns={\n",
    "                    'ref_area_code': 'region'\n",
    "                })\n",
    "            elif (data.iloc[0]['is--continent'] == 1):\n",
    "                NewDirectory = Directory.replace('ref_area_code','continent')\n",
    "                newFileName = newFileName1.replace('ref_area_code','continent')\n",
    "                myDS = myDS.rename(columns={\n",
    "                    'ref_area_code': 'continent'\n",
    "                })\n",
    "            elif (data.iloc[0]['is--country'] == 1):\n",
    "                NewDirectory = Directory.replace('ref_area_code','country')\n",
    "                newFileName = newFileName1.replace('ref_area_code','country')\n",
    "                myDS = myDS.rename(columns={\n",
    "                    'ref_area_code': 'country'\n",
    "                })\n",
    "            createDirectory(NewDirectory)\n",
    "            path = os.path.join(out_dir,NewDirectory+'/'+newFileName.format(geo))\n",
    "\n",
    "            myDS.to_csv(path, index=False, float_format='%.15g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_Files_nonEst(source, variant, gender, TypeBy):\n",
    "    #load file using pandas\n",
    "    data = pd.read_excel(source, sheetname= variant, skiprows=16, na_values='…')\n",
    "    data = data.drop(['Index', 'Notes'], axis = 1)\n",
    "    \n",
    "    #rename country column and country code column\n",
    "    data = data.rename(columns={\n",
    "        #'Major area, region, country or area *': 'Ref_Area',\n",
    "        'Country code': 'Ref_Area_Code'\n",
    "    })\n",
    "    #year column is present in Age Type sheets\n",
    "    \n",
    "    data = data.rename(columns={\n",
    "    'Reference date (as of 1 July)': 'Year'\n",
    "    })\n",
    "    #insert Gender column\n",
    "    data.insert(3, 'Gender', gender)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetDataFromWorkBook(source, gender, indicator, TypeBy):\n",
    "    all_variants = []\n",
    "\n",
    "    #pandas excel file fun.\n",
    "    wbb = pd.ExcelFile(source)\n",
    "\n",
    "    #iterate through each SHEET except \"NOTES\"\n",
    "    for sheetName in wbb.sheet_names:\n",
    "        if(sheetName == 'NOTES'):\n",
    "            #ignore NOTES sheet since we are not collecting metadata yet\n",
    "            continue\n",
    "        else:\n",
    "            #first load the files\n",
    "            mydata = load_Files_new(source, sheetName, gender, TypeBy)\n",
    "            #mydata = mydata.drop(['Ref_Area'], axis=1)\n",
    "            #mydata = mydata.set_index(['Ref_Area_Code','Variant', 'Year'])\n",
    "            #print(mydata.Gender.unique())\n",
    "            all_variants.append(mydata)\n",
    "    return all_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetNonEstimateDataFromWorkBook(source, gender, indicator, TypeBy):\n",
    "    all_variants = []\n",
    "\n",
    "    #pandas excel file fun.\n",
    "    wbb = pd.ExcelFile(source)\n",
    "\n",
    "    #iterate through each SHEET except \"NOTES\"\n",
    "    for sheetName in wbb.sheet_names:\n",
    "        if(sheetName == 'NOTES' or sheetName == 'ESTIMATES' or sheetName == 'MEDIUM VARIANT'):\n",
    "            #ignore NOTES sheet since we are not collecting metadata yet\n",
    "            continue\n",
    "        else:\n",
    "            #first load the files\n",
    "            mydata = load_Files_new(source, sheetName, gender, TypeBy)\n",
    "            #mydata = mydata.drop(['Ref_Area'], axis=1)\n",
    "            #mydata = mydata.set_index(['Ref_Area_Code','Variant', 'Year'])\n",
    "            #print(mydata.Gender.unique())\n",
    "            all_variants.append(mydata)\n",
    "\n",
    "    return all_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetNonESTIMATE_MidVariant_Data(FileName, SEX, Indicator, TypeBY , hasGender):\n",
    "    if(\";\" in FileName):\n",
    "        #if yes then run the method for each files and merge the two dataset.\n",
    "        files = FileName.split(\";\")\n",
    "        ds_allSex = []\n",
    "        #iterate through files then\n",
    "        for file in files:\n",
    "            if \"_MALE\" in file:\n",
    "                SEX = \"male\"\n",
    "            elif \"_FEMALE\" in file:\n",
    "                SEX = \"female\"\n",
    "            ds_sex = GetNonEstimateDataFromWorkBook(\"source/\"+file, SEX, Indicator, TypeBY) \n",
    "            ds_allSex.append(ds_sex)\n",
    "\n",
    "        #concat all the sheets and files together as one list\n",
    "        mainds = []\n",
    "        for dss in ds_allSex:\n",
    "            for dss1 in dss:\n",
    "                mainds.append(dss1)\n",
    "        #dataSet = sortDataSets(mainds, TypeBY, FileName)\n",
    "        dataSet = pd.concat(mainds, ignore_index=True) \n",
    "        \n",
    "    else:\n",
    "        ds_sex = GetNonEstimateDataFromWorkBook(\"source/\"+FileName, SEX, Indicator, TypeBY) \n",
    "        dataSet = pd.concat(ds_sex, ignore_index=True) \n",
    "    dataSet = dataSet.rename(columns={\n",
    "    'Reference date (as of 1 July)': 'Year'\n",
    "    })\n",
    "    \n",
    "    dataSet['Variant'] = [ x.lower().replace(' ', '_').replace('-','_') for x in dataSet['Variant']]\n",
    "    if hasGender:\n",
    "        newDS = pd.melt(dataSet, id_vars=['Variant',  'Ref_Area_Code',  'Year', 'Gender'], var_name='agebroad', value_name=Indicator)\n",
    "    else:\n",
    "        newDS = pd.melt(dataSet, id_vars=['Variant',  'Ref_Area_Code',  'Year'], var_name='agebroad', value_name=Indicator)\n",
    "    newDS['agebroad'] = [ x.replace('-','_').replace('+','plus').replace('Total','total').strip() for x in newDS['agebroad']]\n",
    "    newDS.columns = list(map(to_concept_id, newDS.columns))\n",
    "\n",
    "    return newDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def callBroadAgeFormat(FileName, Indicator, TypeBY, OtherFiles, Directory):\n",
    "    print('creating files for : ' + Indicator)\n",
    "    hasGender = None\n",
    "    if(\";\" in FileName):\n",
    "        files = FileName.split(\";\")\n",
    "        ds_allSex = []\n",
    "        #iterate through files then\n",
    "        for file in files:\n",
    "            if \"_MALE\" in file:\n",
    "                hasGender = True\n",
    "                SEX = \"male\"\n",
    "                ds_sex = GetDataFromWorkBook(\"source/\"+file, SEX, Indicator, TypeBY )\n",
    "            elif \"_FEMALE\" in file:\n",
    "                hasGender = True\n",
    "                SEX = \"female\"\n",
    "                ds_sex = GetDataFromWorkBook(\"source/\"+file, SEX, Indicator, TypeBY )\n",
    "            ds_allSex.append(ds_sex)\n",
    "                                                #concat all the sheets and files together as one list\n",
    "        mainds = []\n",
    "        for dss in ds_allSex:\n",
    "            for dss1 in dss:\n",
    "                mainds.append(dss1)\n",
    "        ds = pd.concat(mainds, ignore_index = True)\n",
    "    else:\n",
    "        SEX = ''\n",
    "        ds_vals = GetDataFromWorkBook(\"source/\"+FileName, SEX, Indicator, TypeBY )\n",
    "        ds = pd.concat(ds_vals, ignore_index = True)\n",
    "        hasGender = False\n",
    "\n",
    "    #update the column names and then melt it\n",
    "    for i, row in enumerate(BroadAgeMap.values):\n",
    "        BroadAgeOld, BroadAgeNew = row\n",
    "        ds = ds.rename(columns={BroadAgeOld : BroadAgeNew})\n",
    "\n",
    "    ds = ds.rename(columns = {'Reference date (as of 1 July)': 'Year'})\n",
    "    if hasGender:\n",
    "        ds = pd.melt(ds, id_vars=[  'Ref_Area_Code','Variant',  'Year', 'Gender'], var_name='agebroad', value_name=Indicator)\n",
    "    else:\n",
    "        ds = pd.melt(ds, id_vars=[  'Ref_Area_Code', 'Variant', 'Year'], var_name='agebroad', value_name=Indicator)\n",
    "    ds['Variant'] = [ x.lower().replace(' ', '_').replace('-','_') for x in ds['Variant']]\n",
    "\n",
    "    ds.columns = list(map(to_concept_id, ds.columns))\n",
    "\n",
    "    #now get the non ESTIMATE and MIDVariant from other files\n",
    "    other_ds = GetNonESTIMATE_MidVariant_Data(OtherFiles, SEX, Indicator, TypeBY, hasGender )\n",
    "\n",
    "    #concatenate the two data sets/frames\n",
    "    final_ds = pd.concat([ds, other_ds], ignore_index=True)\n",
    "    final_ds = final_ds.drop_duplicates()\n",
    "    if hasGender:\n",
    "        final_ds = final_ds.sort_values(by=['ref_area_code', 'year','variant', 'gender'])\n",
    "    else:\n",
    "        final_ds = final_ds.sort_values(by=['ref_area_code', 'year','variant'])\n",
    "\n",
    "    #now create the final files and directory\n",
    "    createDataFiles_simple(final_ds, Directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def callDependencyFormat(ds, FileName, Indicator, TypeBY, OtherFiles, Directory, checkOtherFiles, isGender):\n",
    "    \n",
    "    ds = ds.rename(columns = {'Reference date (as of 1 July)': 'Year'})\n",
    "    \n",
    "    for i, row in enumerate(DependencyMap.values):\n",
    "        DependencyOld, DependencyNew, DepenndencyExtraFiles = row\n",
    "        print('creating files for : ' + DependencyNew)\n",
    "        #process the main file first\n",
    "        ds_stage = ds.rename(columns = {DependencyOld: DependencyNew})\n",
    "        \n",
    "        ds_stage.columns = list(map(to_concept_id, ds_stage.columns))\n",
    "        ds_stage['variant'] = [ x.lower().replace(' ', '_').replace('-','_') for x in ds_stage['variant']]\n",
    "        if isGender:\n",
    "            firstDS = ds_stage[['variant','ref_area_code','year','gender',DependencyNew.lower()]].copy()\n",
    "        else:\n",
    "            firstDS = ds_stage[['variant','ref_area_code','year',DependencyNew.lower()]].copy()\n",
    "        \n",
    "        if checkOtherFiles:\n",
    "            #get the other files\n",
    "            vals = GetNonEstimateDataFromWorkBook(\"source/\"+DepenndencyExtraFiles, 'gender', Indicator, TypeBY)\n",
    "            other_ds = pd.concat(vals, ignore_index=True) \n",
    "            other_ds = pd.melt(other_ds, id_vars=[  'Variant', 'Ref_Area_Code'], var_name='Year', value_name=DependencyNew)\n",
    "            other_ds.columns = list(map(to_concept_id, other_ds.columns))        \n",
    "            other_ds['variant'] = [ x.lower().replace(' ', '_').replace('-','_') for x in other_ds['variant']]\n",
    "\n",
    "            final_ds = pd.concat([firstDS, other_ds], ignore_index=True) \n",
    "\n",
    "            #change directory name with indicator name\n",
    "            newDirectory = Directory.lower().replace('newformat', DependencyNew)\n",
    "\n",
    "            #now create the final files and directory\n",
    "            createDataFiles_simple(final_ds, newDirectory)\n",
    "        else:\n",
    "            #change directory name with indicator name\n",
    "            newDirectory = Directory.lower().replace('newformat', DependencyNew)\n",
    "            \n",
    "            #now create the final files and directory\n",
    "            createDataFiles_simple(firstDS, newDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#MAIN Function. Calls the metadata.xslx file and iterate through each file\n",
    "#supports reading multiple files and concatenating them to one dataset as well.\n",
    "def callDataPointFiles(metadata_df, cdf):\n",
    "    \n",
    "    df = metadata_df\n",
    "    MainStart = time.time()\n",
    "    for i, row in enumerate(metadata_df.values):\n",
    "        start = time.time()\n",
    "        \n",
    "        #print(row)\n",
    "        #date = metadata_df.index[i]\n",
    "        FileName, TypeBY, SEX, Indicator, Directory, Include, OtherFiles, name, description, url = row\n",
    "        newFileName = Directory.lower()\n",
    "        newFileName = newFileName.replace(\"ref_area_code\", \"ref_area_code-{}\")\n",
    "        newFileName = newFileName + \".csv\"\n",
    "\n",
    "        if(Include == 1):\n",
    "            #if (Indicator.lower() == \"feminityratio_femaleper100male\"):\n",
    "            if(TypeBY == \"DemographyFormat\" ):\n",
    "                ds1 = GetDataFromWorkBook(\"source/\"+FileName, SEX, Indicator, TypeBY )\n",
    "                ds = pd.concat(ds1, ignore_index = True)\n",
    "                \n",
    "                createDataFiles_new(ds)\n",
    "\n",
    "                end = time.time()\n",
    "                print ('Time Taken: ' + str(end-start)) \n",
    "            elif(TypeBY == \"BroadAgeFormat\"):\n",
    "                #this format has multiple files with different format i.e broad age is given in textual form in \n",
    "                #first format but then it's in coded form in another file. Method below reads both files and then concatenate\n",
    "                #data between two files. From one file we get Estimate + mid variant and from Another file we get rest of variants\n",
    "                callBroadAgeFormat(FileName, Indicator, TypeBY, OtherFiles, Directory)\n",
    "                end = time.time()\n",
    "                print ('Time Taken: ' + str(end-start)) \n",
    "            elif(TypeBY == \"DependencyFormat\"):\n",
    "                #this format is combination of Demography Format and Broad Age Format.\n",
    "                #this file contains multiple indicators just like Demography Format\n",
    "                #HOWEVER it need to be mearged with the same indicator from other files with non ESTIMATE and MID variant\n",
    "                \n",
    "                #so get data first just like demography format\n",
    "                \n",
    "                #if file has male and female then process them only since other files doesn't exist\n",
    "                if(\";\" in FileName):\n",
    "                    files = FileName.split(\";\")\n",
    "                    ds_allSex = []\n",
    "                    #iterate through files then\n",
    "                    for file in files:\n",
    "                        if \"_MALE\" in file:\n",
    "                            hasGender = True\n",
    "                            SEX = \"male\"\n",
    "                            ds_sex = GetDataFromWorkBook(\"source/\"+file, SEX, Indicator, TypeBY )\n",
    "                            ds_sex_new = pd.concat(ds_sex, ignore_index = True)\n",
    "                            ds_sex_new['Gender'] = 'male'\n",
    "                        elif \"_FEMALE\" in file:\n",
    "                            hasGender = True\n",
    "                            SEX = \"female\"\n",
    "                            ds_sex = GetDataFromWorkBook(\"source/\"+file, SEX, Indicator, TypeBY )\n",
    "                            ds_sex_new = pd.concat(ds_sex, ignore_index = True)\n",
    "                            ds_sex_new['Gender'] = 'female'\n",
    "                        ds_allSex.append(ds_sex_new)\n",
    "                    ds = pd.concat(ds_allSex, ignore_index = True)\n",
    "\n",
    "                    #change Directory name:\n",
    "                    myDir = Directory.lower().replace('newformat',Indicator)\n",
    "                    \n",
    "                    callDependencyFormat(ds, FileName, Indicator, TypeBY, OtherFiles, Directory, False, True)\n",
    "                    end = time.time()\n",
    "                    print ('Time Taken: ' + str(end-start)) \n",
    "                else:\n",
    "                    ds1 = GetDataFromWorkBook(\"source/\"+FileName, SEX, Indicator, TypeBY )\n",
    "                    ds = pd.concat(ds1, ignore_index = True)\n",
    "                    \n",
    "                    #print('otherfilesname: ' + OtherFiles)\n",
    "                    \n",
    "                    #now get the data from other files\n",
    "                    #callDependencyFormat(ds, FileName, Indicator, TypeBY, OtherFiles, Directory, True, False)\n",
    "                    end = time.time()\n",
    "                    print ('Time Taken: ' + str(end-start)) \n",
    "\n",
    "            if (TypeBY == \"Year\" or TypeBY == \"Age\" or TypeBY == \"YearInterval\" or TypeBY == \"AgeYearInterval\"):\n",
    "                print( str(i+1) + ' of '+ str(metadata_df.shape[0]) +' -- ' + FileName)\n",
    "\n",
    "                #update concept name & description in metadata file\n",
    "                #at the moment same file is being read twice(once for note and desc and then for main dataset)\n",
    "                #this could be made more efficient by reading file only once\n",
    "                cdf = updateMetaData(cdf, TypeBY, Directory, FileName, Indicator)\n",
    "\n",
    "                #check if FileName has two or more files. for ex same dimensions with male and female\n",
    "                if(\";\" in FileName):\n",
    "                    #if yes then run the method for each files and merge the two dataset.\n",
    "                    files = FileName.split(\";\")\n",
    "                    ds_allSex = []\n",
    "                    #iterate through files then\n",
    "                    for file in files:\n",
    "                        if \"_MALE\" in file:\n",
    "                            SEX = \"male\"\n",
    "                        elif \"_FEMALE\" in file:\n",
    "                            SEX = \"female\"\n",
    "                        ds_sex = GetDataFromWorkBookSheets(\"source/\"+file, SEX, Indicator, TypeBY) \n",
    "                        ds_allSex.append(ds_sex)\n",
    "\n",
    "                    #concat all the sheets and files together as one list\n",
    "                    mainds = []\n",
    "                    for dss in ds_allSex:\n",
    "                        for dss1 in dss:\n",
    "                            mainds.append(dss1)\n",
    "                    dataSet = sortDataSets(mainds, TypeBY, FileName)\n",
    "                else:\n",
    "                    ds_sex = GetDataFromWorkBookSheets(\"source/\"+FileName, SEX, Indicator, TypeBY) \n",
    "                    dataSet = sortDataSets(ds_sex, TypeBY, FileName)\n",
    "\n",
    "                dataSet = dataSet.drop_duplicates()\n",
    "\n",
    "                #create files from dataset\n",
    "                GenerateYearFormatFiles(dataSet, Directory.lower(), newFileName, SEX, Ref_Area_List)\n",
    "\n",
    "                end = time.time()            \n",
    "                print ('Time Taken: ' + str(end-start)) \n",
    "                #break\n",
    "    FinalEnd = time.time()\n",
    "    print ('Total Time For All Files: ' + str(FinalEnd-MainStart))\n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all functions here are to generate the concepts and entities files.\n",
    "def generateEntities_Gender():\n",
    "    cdf = pd.DataFrame([], columns=['gender'])\n",
    "    cdf['gender'] = ['male', 'female']\n",
    "    \n",
    "    path = os.path.join(out_dir, 'ddf--entities--gender.csv')\n",
    "    cdf.to_csv(path, index=False)\n",
    "\n",
    "def generateEntities_Freq():\n",
    "    cdf = pd.DataFrame([], columns=['freq'])\n",
    "    cdf['freq'] = ['5yearly']\n",
    "    \n",
    "    path = os.path.join(out_dir, 'ddf--entities--freq.csv')\n",
    "    cdf.to_csv(path, index=False)\n",
    "def generateEntities_Variant():\n",
    "    variant = [x.lower().replace(' ', '_').replace('-', '_') for x in variants if x != 'NOTES']\n",
    "    \n",
    "    cdf = pd.DataFrame([], columns=['variant'])\n",
    "    cdf['variant'] = variant\n",
    "    \n",
    "    path = os.path.join(out_dir, 'ddf--entities--variant.csv')\n",
    "    cdf.to_csv(path, index=False)\n",
    "def generateEntities_AgeGroups():\n",
    "    cdf = pd.DataFrame([], columns=['agebroad','is--agebroad'])\n",
    "    cdf['agebroad'] = [ x.replace('-','_').replace('+','plus').replace('Total','total').strip() for x in sorted(set(ageBroad))]\n",
    "    cdf['is--agebroad'] = 'TRUE'   \n",
    "    cdf.loc[len(cdf)] = ['0','TRUE']\n",
    "    path = os.path.join(out_dir, 'ddf--entities--age--agebroad.csv')\n",
    "    cdf.to_csv(path, index=False)\n",
    "    \n",
    "    cdf1 = pd.DataFrame([], columns=['age1yearinterval','is--age1yearinterval'])\n",
    "    #print(age1YrInterval)\n",
    "    cdf1['age1yearinterval'] = [ x.replace('-','_').replace('+','plus').replace('Total','total').strip() for x in sorted(set(age1YrInterval))]\n",
    "    cdf1['is--age1yearinterval'] = 'TRUE'    \n",
    "    path = os.path.join(out_dir, 'ddf--entities--age--age1yearinterval.csv')\n",
    "    cdf1.to_csv(path, index=False)\n",
    "    \n",
    "    cdf2 = pd.DataFrame([], columns=['age5yearinterval','is--age5yearinterval'])\n",
    "    cdf2['age5yearinterval'] = [ x.replace('-','_').replace('+','plus').replace('Total','total').strip() for x in sorted(set(age5YrInterval))]\n",
    "    cdf2['is--age5yearinterval'] = 'TRUE'    \n",
    "    path = os.path.join(out_dir, 'ddf--entities--age--age5yearinterval.csv')\n",
    "    cdf2.to_csv(path, index=False)\n",
    "\n",
    "    \n",
    "def generateEntities_RefAreaCode():\n",
    "    Ref_Area_List = pd.read_excel('source/countrymetadata.xlsx', parse_cols = \"A:G\")\n",
    "    \n",
    "    cdf = pd.DataFrame([], columns=['country', 'name','is--country', 'parent'])\n",
    "    cdf['country'] = Ref_Area_List.loc[Ref_Area_List['is--country'] == 1, 'Code']\n",
    "    cdf['name'] = Ref_Area_List.loc[Ref_Area_List['is--country'] == 1, 'Region']\n",
    "    cdf['parent'] = Ref_Area_List.loc[Ref_Area_List['is--country'] == 1, 'Parent']\n",
    "    cdf['is--country'] = 'TRUE'    \n",
    "    path = os.path.join(out_dir, 'ddf--entities--geo--country.csv')\n",
    "    cdf.to_csv(path, index=False)\n",
    "    \n",
    "    cdf1 = pd.DataFrame([], columns=['region','name','is--region','parent'])\n",
    "    cdf1['region'] = Ref_Area_List.loc[Ref_Area_List['is--region'] == 1, 'Code']\n",
    "    cdf1['name'] = Ref_Area_List.loc[Ref_Area_List['is--region'] == 1, 'Region']\n",
    "    cdf1['parent'] = Ref_Area_List.loc[Ref_Area_List['is--region'] == 1, 'Parent']\n",
    "    cdf1['is--region'] = 'TRUE'\n",
    "    path = os.path.join(out_dir, 'ddf--entities--geo--region.csv')\n",
    "    cdf1.to_csv(path, index=False)\n",
    "    \n",
    "    cdf2 = pd.DataFrame([], columns=['continent','name','is--continent','parent'])\n",
    "    cdf2['continent'] = Ref_Area_List.loc[Ref_Area_List['is--continent'] == 1, 'Code']\n",
    "    cdf2['name'] = Ref_Area_List.loc[Ref_Area_List['is--continent'] == 1, 'Region']\n",
    "    cdf2['parent'] = Ref_Area_List.loc[Ref_Area_List['is--continent'] == 1, 'Parent']\n",
    "    cdf2['is--continent'] = 'TRUE'\n",
    "    path = os.path.join(out_dir, 'ddf--entities--geo--continent.csv')\n",
    "    cdf2.to_csv(path, index=False)\n",
    "    \n",
    "    cdf3 = pd.DataFrame([], columns=['global','name','is--global'])\n",
    "    cdf3['global'] = Ref_Area_List.loc[Ref_Area_List['is--world'] == 1, 'Code']\n",
    "    cdf3['name'] = Ref_Area_List.loc[Ref_Area_List['is--world'] == 1, 'Region']\n",
    "    cdf3['is--global'] = 'TRUE'\n",
    "    path = os.path.join(out_dir, 'ddf--entities--geo--global.csv')\n",
    "    cdf3.to_csv(path, index=False)\n",
    "    \n",
    "def createConceptsDF(metadata):\n",
    "    concept_name = ['Year', 'Age', 'Gender', 'Freq','Variant' ,'Geo', 'Country', \n",
    "                    'Region', 'Continent', 'Global','AgeBroad', 'Age1YearInterval','Age5YearInterval'\n",
    "                   ,'name', 'parent', 'domain','description', 'sourceurl']\n",
    "    \n",
    "    concept_name = concept_name + list(metadata.Indicator.unique())\n",
    "    concept_name = concept_name + list(['infantmortality','populationchange','populationnaturalchange','totalpopulationannualdoubletime',\n",
    "                                      'totalsurvivors_under_one_yearage','under_five_mortality'])\n",
    "    #print(concept_name)\n",
    "\n",
    "    # 53 print(len(list(metadata.Indicator.unique())))\n",
    "    \n",
    "    concepts = list(map(to_concept_id, concept_name))\n",
    "    cdf = pd.DataFrame([], columns=['concept', 'concept_type', 'domain', 'name', 'description', 'sourceurl'])\n",
    "    cdf['concept'] = concepts\n",
    "    cdf['concept_type'] = 'measure'\n",
    "    cdf['concept_type'].iloc[1:6] = 'entity_domain'\n",
    "    cdf['concept_type'].iloc[6:13] = 'entity_set'\n",
    "    cdf['concept_type'].iloc[13:18] = 'string'\n",
    "    cdf['domain'].iloc[6:10] = 'geo'\n",
    "    cdf['domain'].iloc[10:13] = 'age'\n",
    "    cdf['concept_type'].iloc[0] = 'time'\n",
    "    \n",
    "    return cdf\n",
    "    \n",
    "def generateConcepts(cdf):\n",
    "    path = os.path.join(out_dir, 'ddf--concepts.csv')\n",
    "    cdf.to_csv(path, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 86 -- WPP2017_FERT_F03_CRUDE_BIRTH_RATE.xlsx\n",
      "     Variant Region, subregion, country or area *  Ref_Area_Code     Freq  \\\n",
      "0  Estimates                                WORLD            900  5yearly   \n",
      "\n",
      "  Gender  1950-1955  1955-1960  1960-1965  1965-1970  1970-1975  1975-1980  \\\n",
      "0     na     36.876     35.379     35.373     34.001      31.42     28.523   \n",
      "\n",
      "   1980-1985  1985-1990  1990-1995  1995-2000  2000-2005  2005-2010  2010-2015  \n",
      "0     27.863     27.419     24.274     21.966     20.896     20.311     19.562  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "labels ['Ref_Area'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-70f284f6ba35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#create datapoints and create all files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallDataPointFiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#generate concepts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-7ee7422cc48f>\u001b[0m in \u001b[0;36mcallDataPointFiles\u001b[0;34m(metadata_df, cdf)\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mdataSet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msortDataSets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmainds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeBY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                     \u001b[0mds_sex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetDataFromWorkBookSheets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"source/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mFileName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndicator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeBY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m                     \u001b[0mdataSet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msortDataSets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_sex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeBY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-070c79548f8d>\u001b[0m in \u001b[0;36mGetDataFromWorkBookSheets\u001b[0;34m(source, gender, indicator, TypeBy)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mmydata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_Files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheetName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeBy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmydata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mmydata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmydata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ref_Area'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;31m#based on File format type apply the index and set the column value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeBy\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Age\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harpalshergill/anaconda/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, level, inplace, errors)\u001b[0m\n\u001b[1;32m   1875\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1877\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1878\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/harpalshergill/anaconda/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3049\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3050\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3051\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3052\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3053\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['Ref_Area'] not contained in axis"
     ]
    }
   ],
   "source": [
    "#createConceptDF\n",
    "cdf = createConceptsDF(metadata_df)\n",
    "\n",
    "#create datapoints and create all files\n",
    "cdf = callDataPointFiles(metadata_df, cdf)\n",
    "\n",
    "#generate concepts\n",
    "generateConcepts(cdf)\n",
    "\n",
    "#generate variants\n",
    "generateEntities_Variant()\n",
    "\n",
    "#generate countries/world/regions\n",
    "generateEntities_RefAreaCode()\n",
    "\n",
    "#generate age groups\n",
    "generateEntities_AgeGroups()\n",
    "\n",
    "#generate gender\n",
    "generateEntities_Gender()\n",
    "\n",
    "#generate freq\n",
    "generateEntities_Freq()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
